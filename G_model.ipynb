{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv2DTranspose, Conv2D, BatchNormalization,\n",
    "    LeakyReLU, Dropout, Reshape, Flatten\n",
    ")\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "''' basic package '''\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)  # mean=0, stddev=0.02\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "\n",
    "    # 因為預設會使用 batchnorm，所以不需要加 bias\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "\n",
    "    # 還記得 Vanilla GAN 裡提到的 Conv2DTranspose 的介紹嗎？忘記了可以再回去看喔！\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "def Generator():\n",
    "    OUTPUT_CHANNELS = 3\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False),  # (bs, 128, 128, 64)\n",
    "        downsample(128, 4),  # (bs, 64, 64, 128)\n",
    "        downsample(256, 4),  # (bs, 32, 32, 256)\n",
    "        downsample(512, 4),  # (bs, 16, 16, 512)\n",
    "        downsample(512, 4),  # (bs, 8, 8, 512)\n",
    "        downsample(512, 4),  # (bs, 4, 4, 512)\n",
    "        downsample(512, 4),  # (bs, 2, 2, 512)\n",
    "        downsample(512, 4),  # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4),  # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4),  # (bs, 32, 32, 512)\n",
    "        upsample(128, 4),  # (bs, 64, 64, 256)\n",
    "        upsample(64, 4),  # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    # 最後 output 的 range 要在 -1 ~ 1 之間，所以選用的 activation function 是 \"tanh\"\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                           strides=2,\n",
    "                                           padding='same',\n",
    "                                           kernel_initializer=initializer,\n",
    "                                           activation='tanh')  # (bs, 256, 256, 3)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    inputs = tf.keras.layers.Input(shape=[None, None, 3])\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling\n",
    "    # 用一個 list 將每層的輸出存起來，之後再 Upsampling 時可以使用\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    skips = reversed(skips[:-1])  # 把 skip connections 的值存起來並顛倒，後面在 upsampling 時會用到\n",
    "\n",
    "    # Upsampling 和 skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[None, None, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[None, None, 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar], axis=-1)  # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1)  # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2)  # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                  kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "\n",
    "def generate_images(model, test_input):\n",
    "\n",
    "    prediction = model(test_input, training=True)  # 這邊設 training=True 是希望能得到 test_input 的一些統計量\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "    pre_imgary=prediction[0].numpy()\n",
    "    pre_imgary1=(pre_imgary+1)*127.5\n",
    "    #print(pre_imgary1)\n",
    "    cv2.imwrite('./output.jpg', pre_imgary1)\n",
    "    #for i in range(2):\n",
    "        #plt.subplot(1, 2, i+1)\n",
    "        #plt.title(title[i])\n",
    "        # 將圖片像素值調整至 0 - 1 之間才能 plot\n",
    "        #plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        #plt.axis('off')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def main():    \n",
    "    OUTPUT_CHANNELS = 3\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                     discriminator_optimizer=discriminator_optimizer,\n",
    "                                     generator=generator,\n",
    "                                     discriminator=discriminator)\n",
    "\n",
    "\n",
    "    checkpoint_dir = './training_checkpoints'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    image = tf.io.read_file('./pin1.jpg')\n",
    "    image = tf.image.decode_jpeg(image,channels=3)\n",
    "        # 將 image decode 為 unit8 的 tensor\n",
    "    image=tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [256, 256],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = (image / 127.5) - 1\n",
    "    generate_images(generator, image[tf.newaxis, ...] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
